\documentclass{article}
\usepackage[utf8]{inputenc}

\usepackage{color}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{fullpage}
\usepackage{algorithmic}
\DeclareMathOperator*{\argmin}{argmin}
\algsetup{linenosize=\small}
\usepackage[table,xcdraw]{xcolor}
\usepackage{multirow}
\usepackage[super]{nth}
\usepackage{graphicx}
\usepackage{caption}
\usepackage[labelformat=simple]{subcaption}
\usepackage{comment}
\usepackage{setspace}
\usepackage{textcomp}
\usepackage{xspace}
\usepackage{siunitx}
\usepackage{epsfig}
\usepackage{epstopdf}
\usepackage{soul}
\usepackage{url}
\usepackage{tablefootnote}
\DeclareMathOperator{\E}{\mathbb{E}} % Expectation Symbol
\usepackage[linesnumbered,ruled]{algorithm2e}
\usepackage{booktabs}



\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}



\title{A Novel Mechanism for Access Point Association in IEEE 802.11 WLANs}
\author{Marc Carrascosa, Boris Bellalta and Francesc Wilhelmi}
\date{November 2017}

\begin{document}

\maketitle

\begin{abstract}
	Abstract here. To be done at the end.
\end{abstract}

\tableofcontents
\newpage

%%%%%%%%%%%%%%%%%%%
% INTRODUCTION     
%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\label{section:introduction}
	
	% MOTIVATION
	\subsection{Motivation}
	\label{section:motivation}
		\textcolor{red}{Explain why AP association is important. Motivate the problem a bit by mentioning density issues in next-generation WLANs, problems in current association procedures (e.g., keeping the signal forever), etc.}

	The default method used in 802.11 for STAs to find and associate to an AP is based on the Signal to Noise Ratio (SNR) they receive from each AP. This method works for home deployments where a single AP is present, but in multi AP deployments it can lead to an unfair system with starved nodes. The growing popularity of wi-fi for massive deployments in malls, airports and the like has shown the deficiencies in the Strongest Signal First method \cite{judd2004}\cite{anand2002}, which fails to take into consideration the AP load or the topology of the network, as well as not reassociating until absolutely necessary, even if the node could get a much better service elsewhere.
	
	Other methods attempted have to use more metrics than SNR for their decision making, such as potential bandwidth estimation \cite{vasudevan2005} or proportional fairness\cite{Li2014}. This more often than not means higher computation time and possible delays that need to be taken into consideration. This computation can be done by the STAs themselves in a decentralized fashion or by a central hub that makes the decisions and then transmits them to the STAs. 
	
	
	Revisions in the 802.11 protocol seem to take this into consideration, 802.11r brought the neighbor report, which has the AP obtain information on other APs and relay it to its STAs to help them make informed decisions on reassociations. 
	
	The recent popularity of machine learning is also worth take into account, as it brings new ways of analyzing all this information and making better decisions when finding multiple APs.
	
	
	
	% CONTRIBUTIOn
	\subsection{Contributions}
	\label{section:contributions}
		\textcolor{red}{To do: make a list of contributions done in this paper (e.g., we review the previous work in AP association in WLANs, we implement a learning mechanism for AP association, we provide a quantitative analysis on different AP association strategies, etc.)}
		
		Our intent in this document is to showcase the inefficiency of the SSF method in multi AP deployments by using several methods of association selection and comparing them in both fairness and throughput achieved.
		
		We will try a greedy mechanism in which each STA tries to improve its own throughput while disregarding the effect on the rest of the nodes, this method will also show that the order in which the STAs reassociate is an important factor that can create a deadlock in the network, stopping it from reaching a better solution or leaving it in a worse one than before.
		
		We will also try centralized methods in which the effect of every single reassociation is anlayzed before being allowed, by comparing the aggregate throughput of the netire network as well as the proportional fairness achieved. By only allowing the changes that improve this metrics, we stop the STAs to find a better solution for themselves that leaves other users with a bad service. This simple solution is also affected by the order of the reassociations however, and can also prevent itself from reaching an optimal solution.
		
		Finally we will try Thompson sampling, which uses sampling from a normal distribution to check different scenarios, updating the parameters of the distribution with each iteration to achieve better results over time. In this particular case all of the STAs switch at the same time, and due to the randomness that is present in the algorithm, it prevents itself from deadlocking.
		
		
	% STRUCTURE
	\subsection{Article Structure}
	\label{section:article_structure}
			\textcolor{red}{To be done at the end}
			
%%%%%%%%%%%%%%%%%%%
% RELATED WORK     
%%%%%%%%%%%%%%%%%%%
\section{Related Work}
\label{section:related_work}
	\textcolor{red}{To do: start explaining the previous work that is based on SSF and say why it can be harmful to the overall performance. Include new other methods that have been previously used (based on SINR, traffic load, etc.)}
	
	The standard method of AP selection based on signal strength has been shown to lead to uneven load distribution and client distribution among APs \cite{anand2002, balazinska2003}. These analysis of user behaviour show that the number of users on an AP is related to the popularity of the location of said AP, however, peak throughput is not achieved when the maximum number of users is achieved, instead, most peaks in the system depend on the needs of individual users. The results in \cite{balazinska2003} show that 10\% of users are responsible for 40 \% of the load in most APs. 
	
	In \cite{gong2012} STAs use the beacon frames to measure the signal strength of each AP that is in range and compute the throughput they could achieve by associating to each of them. It also categorizes APs by type (g,n,a) and tries to match STAs to APs of similar type. A similar method is used in \cite{sun2004}, where probes are used to measure the AP's available bandwidth to decide which one to choose. Once associated, the STA periodically checks if their individual service requirements are met, and if the service is considered insufficient, probing starts so that a better AP can be found.
	
	Proportional fairness is the preferred compromise between throughput and fairness \cite{Li2014} \cite{amer2016}, it attemps to give each STA a throughput that is proportional to its individual capabilities instead of giving everyone the same. 
	
		\textcolor{blue}{No sé si és rellevant el seguent paràgraf, ho vaig trobar i és interessant però potser s'allunya molt}
		
	A different approach can be found in \cite{tan2004}, where instead of changing the association process, they change the DCF model and the way that each node gets access to the bandwidth. The change is made by going from throughput-based fairness to time-based fairness through the use of a leaky bucket that makes each node transmit an equal amount of time. In the usual DCF model, time-based fairness is only achieved in the  when all nodes share the same characteristics of transmission rate, packet size and error rate. When there are different rates and types of nodes (b,g,a) the network allows them all to send an equal amount of packets, which leads to the slower nodes taking more time than the faster ones, which can be considered unfair. This method allows the faster nodes to get a much higher throughput while keeping the slower ones at a rate equal to the one they would get if the entire network shared their transmission rate. This system is already in place in some devices\cite{aruba2010}.
	
	Some approaches are based on the modern standards and their new features, such as 802.11ac MU-MIMO, the authors of \cite{mimo2017} forego the RSSI values completely and instead concentrate on the channel correlation and MIMO-grouping possibilities in an 11ac network to decide the association, further proving that the default association system is not good enough going forward.
	
We can already find some systems that implement some sort of load balancing and association control. Cisco's APs have an aggressive load balancing option in which the AP accepts all association requests until a certain number of nodes are associated, afterwards, any probe request is met with a response status with code 17, which the STA is expected to honor by attempting association with other APs. A maximum number of code 17 responses can be set, with a maximum of 20, after which the STA is allowed to associate with the original AP \cite{cisco2017}. Further, Cisco's Lightweight Access Point Protocol (LWAPP) also allows for load balancing, the lightweight access points send the probe requests they receive to the controller, and using their loads and the RSSI of the STA as parameters, it chooses which AP will answer the probe \cite{cisco2006}.

Other approaches attempt a more automated solution, relying on the machines to learn the best solution over time. \cite{shin2004} tries to improve the handoff of reassociations by having the STAs keep a list of APs found during scanning organized by RSSI and trying those directly in the future, skipping scanning.
	
	
	
	
%%%%%%%%%%%%%%%%%%%
% STRATEGIES     
%%%%%%%%%%%%%%%%%%%
\section{User Association Strategies \& Metrics}
\label{section:strategies}

	% DECENTRALIZED
	\subsection{Decentralized Approach}
	\label{section:decentralized}
	
		\subsubsection{Selfish Strategy}
		\label{section:selfish}
			STAs only consider their own throughput during the decision-making procedure.
			
		\subsubsection{Shared Strategy}
		\label{section:shared}
			STAs take also into account the throughput at the AP.
	
		\subsubsection{Thompson Sampling}
		\label{section:thompson}
			STAs implement Thompson sampling to learn the best AP for association. 
			
			\textcolor{red}{To do: explain how MABs can be applied to the AP association problem.}	
			
			Thompson sampling \cite{thompson1933likelihood} is a Bayesian algorithm that bases the action-selection procedure according to the prior distributions of the actions' rewards. In particular, it constructs a probabilistic model of the rewards and assumes a prior distribution of the parameters of said model. Given the data collected during the learning procedure, Thompson sampling keeps track of the posterior distribution of the rewards, and pulls arms randomly in a way that the drawing probability of each arm matches the probability of the particular arm being optimal. In practice, this is implemented by sampling the parameter corresponding to each arm from the posterior distribution, and pulling the arm yielding the maximal expected reward under the sampled parameter value.
					
			Thompson sampling is well-known in the Machine Learning community for its excellent empirical performance \cite{CL11}. 
			 
			To the AP association problem, we assume that actions rewards (i.e., user associations) follow a Gaussian distribution, such as suggested in \cite{agrawal2013further}. By standard calculations, it can be verified that the posterior distribution of the rewards under this model is Gaussian with mean 
			\begin{equation}
				\hat{r}_k(t) = \frac{\sum_{w=1:k}^{t-1} r_k(t) }{n_k(t) + 1}
				\nonumber
			\end{equation}
			and variance $\sigma_k^2(t) = \frac{1}{n_k + 1}$, where $n_k$ is the number of times that arm $k$ was drawn until the beginning of round $t$. Thus, implementing Thompson sampling in this model amounts to sampling a parameter $\theta_k$ from the Gaussian distribution $\mathcal{N}\left(\hat{r}_k(t),\sigma_k^2(t)\right)$ and choosing the action with the maximal parameter.   
			
			Our implementation of Thompson sampling to the AP association problem is detailed in Algorithm \ref{alg:thompson_sampling}.
			\textcolor{red}{To do: modify algorithm accordingly.}	
			\begin{algorithm}[h!]
				\SetKwInOut{Input}{Input}
				\SetKwInOut{Output}{Output}		
				Function Thompson Sampling $(\text{SNR},\mathcal{A})$\;
				\Input{SNR: information about the Signal-to-Noise Ratio received at the STA\\$\mathcal{A}$: set of possible actions in \{$a_1, ..., a_K$\}}
				initialize: $t=0$,  for each arm $a_k \in \mathcal{A}$, set $\hat{r}_{k} = 0$ and $n_k = 0$ \\
				\While{active}
				{
					For each arm $a_k \in \mathcal{A}$, sample $\theta_k(t)$ from normal distribution $\mathcal{N}(\hat{r}_{k}, \frac{1}{n_k + 1})$ \\
					Play arm $a_{k} = \underset{k=1,...,K}{\text{argmax }} \theta_k(t) $ \\
					Observe the throughput experienced $\Gamma_t$\\			
					Compute the reward $r_{k,t} = \frac{\Gamma_t}{\Gamma^*}$, where $\Gamma^* = \frac{L}{(T_{STA}+E[\Phi])*2}$ \\
					$ \hat{r}_{k,t} \leftarrow \frac{\hat{r}_{k,t}  n_{k,t} + r_{k,t}}{n_{k,t} + 2}$\\
					$n_{k,t} \leftarrow n_{k,t} + 1$\\
					$t \leftarrow t + 1$
				}
				\caption{Implementation of Multi-Armed Bandits (Thompson sampling) in a STA that aims to associate to the best AP}
				\label{alg:thompson_sampling}
			\end{algorithm}	
			
	% CENTRALIZED
	\subsection{Centralized Approach}
	\label{section:centralized}
	
		\subsubsection{Aggregate Throughput}
		\label{section:aggregate_throughput}
		
		\subsubsection{Proportional Fairness}
		\label{section:prop_fairness}
		
		\subsubsection{Individual + Aggregate Throughput}
		\label{section:mix}

%%%%%%%%%%%%%%%%%%%
% RESULTS     
%%%%%%%%%%%%%%%%%%%
\section{Performance Evaluation}
\label{section:performance_evaluation}

	% SYSTEM MODEL
	\subsection{System Model}
	\label{section:system_model}
		\textcolor{red}{To do: explain how throughput is computed and other simulation considerations (e.g., we first pick the lowest throughput STA). Add also tables with parameters used (CW, Ts...)}	
	\begin{center}\renewcommand*{\arraystretch}{1.25}
\setlength\tabcolsep{15pt}

\begin{tabular}{|c|c|}


  \hline
  
   \textbf{Field} & \textbf{Meaning}\\ \hline
 $\alpha$  & Approximation of the throughput \\\hline
  E[$\Phi$] & Average back-off\\\hline
  CW & Contention window \\\hline
  $T_e$ & Slot left after a successful transmission in DCF \\\hline
  $T_i$ & Successful transmission time for node i\\\hline
  $L_i$ & Length of packets sent by node i\\\hline
  $N_{STAi}$ & Number of STAs connected to AP i\\\hline
  $T_{data}$ & Transmission time for the data alone\\\hline
  $T_{ack}$ & Transmission time for an ACK\\\hline
  $DIFS$ & DCF InterFrame Space \\\hline
  $SIFS$ & Short InterFrame Space \\\hline


\end{tabular}

\end{center}



\begin{center}\renewcommand*{\arraystretch}{1.25}
\setlength\tabcolsep{15pt}

\begin{tabular}{|P{1cm}|P{7.25cm}|}


  \hline
  
   \textbf{Field} & \textbf{Value}\\ \hline
  CW & 16 \\\hline
   E[$\Phi$] & $\frac{CW-1}{2}=\frac{15}{2}=7.5$ \\\hline
  $T_e$ & $9 \mu s$\\\hline
  $L_i$ & 12000 bits\\\hline
  $DIFS$ & $34 \mu s$\\\hline
  $SIFS$ & $16 \mu s$\\\hline


\end{tabular}

\end{center}

Our simulation uses a random topology in which the APs and STAs are distributed at random in a square area. Each of them has a full buffer and the same parameters for the backoff and the size of their packets.

\begin{equation}\label{eq:1}
    T_{i}= T_{data} + SIFS + T_{ack} + DIFS + T_e;
\end{equation}

\begin{equation}\label{eq:2}
    T_{APi}=\frac{\sum T_i}{N_{STAi}}
\end{equation}

\begin{equation}\label{eq:3}
   X_i=E[\Phi_i]+T_i;
\end{equation}
\begin{equation}\label{eq:4}
    \alpha_i = \frac{L_i}{\sum_{j=1}^{N} X_{j}}
\end{equation}

Equation \ref{eq:1} computes the successful transmission time for a packet from a STA, $T_{data}$ is affected by distance to the AP and packet size $L_i$. For the transmission time of an AP, we have equation \ref{eq:2}, which takes the sum of $T_i$ for each STA associated to the AP and divides it by the number of STAs associated.

Equation \ref{eq:3} just adds the average back-off to each transmission time, and finally, equation \ref{eq:4} computes the alpha of the nodes dividing the packet size for each node by the X of every node sensed. We will use this as our throughput.

	% VALIDATION
	\subsection{Validation}
	\label{section:validation}
	
	% RESULTS
	\subsection{Results}
	\label{section:results}

%%%%%%%%%%%%%%%%%%%
% BIBLIOGRAPHY     
%%%%%%%%%%%%%%%%%%%
\section{Conclusions}
\label{section:conclusions}

%%%%%%%%%%%%%%%%%%%
% BIBLIOGRAPHY     
%%%%%%%%%%%%%%%%%%%
\bibliographystyle{unsrt}
\bibliography{bib}

\end{document}
